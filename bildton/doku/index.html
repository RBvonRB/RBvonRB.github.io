<!doctype html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dokumentation Bachelorarbeit</title>
  <link rel="stylesheet" href="style.css">
  <link rel="icon" href="assets/favicon.png">
  <link rel="stylesheet" href="https://use.typekit.net/uad8vgz.css">

</head>

<body>

  <div id="right">
    <div id="toc">
      <h4>Inhaltsverzeichnis<span id="arrow" onclick="unfold()">&#8593;</span></h4>
      </span>
      <ol id="tocOl">
        <li><a id="toc0" href="#intro">Einleitung</a></li>
        <li><a id="toc1" href="#doku">Prozessdokumentation</a></li>
        <ol>
          <li><a id="toc2" href="#chap1">Audiovisualisierungen</a></li>
          <li><a id="toc3" href="#chap2">Erste Versuche Bild-in-Ton-Übersetzung</a></li>
          <li><a id="toc4" href="#chap3">Mögliche konzeptuelle Richtungen</a></li>
          <li><a id="toc5" href="#chap4">Bild-in-Klang-Übersetzung</a></li>
          <li><a id="toc6" href="#chap5">Konzept Live-Performance Tool</a></li>
          <li><a id="toc7" href="#chap6">Konzept Bewegtbild zu Musik</a></li>
        </ol>
        <li><a id="toc8" href="#tool">Tool "Bildton"</a></li>
        <li><a id="toc9" href="#append">Anhang</a></li>
        <ul>
          <li><a id="toc10" href="#schrift">Kulturhistorische Thesisarbeit</a></li>
          <li><a id="toc11" href="#contact">Kontakt</a></li>
          <li><a id="toc12" href="#impr">Impressum</a></li>
        </ul>
      </ol>
    </div>
  </div>

  <div id="main">

    <div id="titel">
      <h1>Bildton</h1>
      <h2>Interaktives Tool zur musikalischen Interpretation von Bewegtbild</h2>
      <p id="sub">Bachelorthesis Raphael Benz
        <br>
        Hochschule für Gestaltung und Kunst Basel, 2020
      </p>
    </div>

    <div class="chap" id="intro">
      <h2>Einleitung</h2>
      <p>Als visueller Gestalter und als Musiker interessiert mich die Schnittstelle zwischen visuellen und auditiven
        Medien, weshalb ich dieses Feld in meiner Bachelorthesis zum Gegenstand der Untersuchung gemacht habe. Ich suche
        nach Wegen, wie visuelle Medien genutzt werden könenn zur Generierung, Komposition und Manipulation von Musik.
        <br>
        Das Endresultat ist <a href="#tool">ein Tool</a>, das Bewegtbilder in Melodien, Geräusche und Rhythmen
        umwandeln kann. Es funktioniert ohne Installation im Browser, aber auch in Kombination mit externer Hard- und
        Software.
      </p>
      <p>Ich bedanke mich herzlich bei meinen Mentoren Prof. Marion Fink, Jinsu Ahn und Ted Davis, meinen
        Kommilitoninnen und Kommilitonen sowie meinen Eltern Suzanne und Marco für ihre Unterstützung bei dieser Arbeit.
      </p>
    </div>

    <div class="chap" id="doku">
      <h2>Prozessdokumentation</h2>
      <p>
        Vorliegend zeige ich meinen gestalterischen Prozess auf, der mich zum Endresultat meiner Arbeit brachte. Der
        Prozess ist chronologisch aufgebaut und endet mit dem interaktiven Tool "Bildton", das meine Bachelorarbeit
        abschliesst.
      </p>
      <div class="chap subchap" id="chap1">
        <h3>Audiovisualisierungen</h3>
        <p>Im zweiwöchigen Workshop zu Beginn der Bachelorarbeit experimentierte ich im Bereich der Audiovisualisierung
          und nutzte verschiedenste Techniken, Geräte und Materialien dazu.</p>


        <div class="videoblock">
          <p class="caption">Visuelle Recherchen zum Thema "Audiovisualisierungen" in Form von analogen VJ-Experimenten
            zu
            bestehenden
            Liedern. (Hellraumprojektor, verschiedene Materialien)</p>
          <iframe src="https://player.vimeo.com/video/443310449" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443310518" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443310618" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443310712" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443310770" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443310799" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>


        <div class="videoblock">
          <p class="caption"> Das Oszilloskop ist ein Gerät zur Messung von elektrischen Spannungen. Auch akustische
            Signale
            können damit
            visualisiert werden, wie in folgenden Versuchen von mir demonstriert wird. (Oszilloskop, Gitarre, digitaler
            Synthesizer)</p>
          <iframe src="https://player.vimeo.com/video/443311258" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443311564" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>


        <div class="videoblock">
          <p class="caption"> In diesem früheren Projekt wurde eine Schale mit Wasser zum Schwingen gebracht, indem sie
            auf einem Basslautsprecher platziert wurde. Die Frequenz des Tones wurde durch die Position des Betrachters
            bestimmt. Das Geschehen in der Wasserschale
            wurde in Echtzeit auf die Wand projiziert, damit es auch aus der Distanz betrachtet werden konnte.
            (Rauminstallation in Zusammenarbeit mit Jana Beyerlein, Audrey Rappolt, Adrian Pirlet)</p>
          <iframe src="https://player.vimeo.com/video/443311719" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443311819" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

        <div class="videoblock">
          <p class="caption"> Verschiedene Arten der Frequenzanalyse von bestehenden Liedern. (Processing) </p>
          <iframe src="https://player.vimeo.com/video/443351739" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443351712" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

        <div class="videoblock">
          <p class="caption"> Ein Spektrogramm zeigt die Frequenzen eines Liedes (Y-Achse) im Zeitverlauf (X-Achse).
            Hier
            sind die Spektrogramme verschiedener musikalischer Genres abgebildet. (Adobe Audition)</p>
          <div class="image"> <img src="assets/pics/jamman_spektrogramm.jpg" alt="Spektogramm Guitar"> </div>
          <div class="image"> <img src="assets/pics/jazz_chetatkins_spektrum_.jpg" alt="Spektogramm Jazz"> </div>
          <div class="image"> <img src="assets/pics/hiphop_cantona_spektrum.jpg" alt="Spektogramm Hip Hop"> </div>
          <div class="image"> <img src="assets/pics/techno_daxJ_spektrum.jpg" alt="Spektogramm Techno"> </div>
        </div>


      </div>


      <div class="chap subchap" id="chap2">

        <h3>Erste Versuche Bild-in-Ton-Übersetzung</h3>
        <p>Ich entschied mich, das Thema der Audiovisualisierungen zu verlassen und in die entgegengesetzte Richtung
          zu experimentieren, also Möglichkeiten der Übersetzung von Bild/Bewegtbild in Klang zu suchen. Diese Art der
          Intermedialität schien mir im Gegensatz zu der Audiovisualisierung noch wenig erforscht und spannend für
          weitere
          Experimente.
          Ich erstellte Programme in Processing und Max MSP, die visuelle Inputs in akustische Outputs verwandeln.
        <p>

        <div class="videoblock videoblockSmall">
          <p class="caption"> Interaktives Zeichentool: Mit der Maus zeichnet man auf die Leinwand. In Echtzeit wird die
            Helligkeit der gesamten Leinwand gemessen. Dieser Helligkeitswert steuert einen Filter an und verändert so
            den
            Klang des
            Rauschens. (Processing)</p>
          <iframe src="https://player.vimeo.com/video/443341214" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

        <div class="videoblock videoblockSmall">
          <p class="caption"> Videoanalyse-Tool: Je heller der Mittelpunkt des Videos, desto heller der Klang des
            Rauschens.
            (Processing) </p>
          <iframe src="https://player.vimeo.com/video/443341232" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

        <div class="videoblock">
          <p class="caption"> In diesem Tool wird die Bewegung eines Videos quantifiziert, indem die Unterschiede
            zwischen
            zwei aufeinanderfolgenden Frames gemessen werden. Dieser Wert steuert die Lautstärke des Rauschens. (Max
            MSP)
          </p>
          <iframe src="https://player.vimeo.com/video/443342321" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443342346" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443342379" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

      </div>


      <div class="chap subchap" id="chap3">

        <h3>Mögliche konzeptuelle Richtungen</h3>
        <p style="margin-bottom: 0"> Nach einigen Experimenten standen mir nun verschiedene Möglichkeiten offen, in
          welche Richtung sich die
          Arbeit
          konzeptuell vertiefen könnte:
        <ul>
          <li>Audio-Video Installation</li>
          <li>Tool zur Generierung von Ton und Visuals</li>
          <li>Game</li>
          <li>Datensonifikation und -visualisierung</li>
        </ul>
        Im Folgenden sind Beispielarbeiten für diese Richtungen aufgelistet.
        </p>

        <div class="videoblock videoblockSmall">
          <p class="caption"> Audio-Video Installation mit Echtzeitübersetzung von Bild in Ton. (Als Beispiel: The
            Instrument vom Musikerduo Voice Crack aus dem Film "Kick that habit") </p>
          <iframe src="https://player.vimeo.com/video/443353795" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

        <div class="videoblock videoblockSmall">
          <p class="caption"> Ein Tool zur Echtzeiterzeugung und Steuerung audiovisueller Erlebnisse (Eigenes Beispiel
            aus
            Schulworkshop zur Audio- und Videosynthese, Processing). </p>
          <iframe src="https://player.vimeo.com/video/321698413" frameBorder="0" allow="autoplay; fullscreen"
            allowfullscreen> </iframe>
        </div>

        <div class="videoblock">
          <p class="caption"> Ein Game, das dank einfacher visuellen Interaktion spielerisch zum Musikmachen verleitet.
            (Beispiele: <a href="http://www.see-this-sound.at/werke/78.html" target="_blank">Music Insects</a> von
            Toshio Iwai, <a href="http://www.see-this-sound.at/werke/73.html" target="_blank">Small Fish</a> von Masaki
            Fujihata, Kiyoshi Furukawa, Wolfgang Münch, <a href="http://www.tmema.org/mis/" target="_blank">Manual Input
              Sessions</a>
            von Tmema)</p>
          <div class="image"> <img src="assets/pics/07_music_insects_large.jpg" alt="Music Insects von Toshio Iwai">
          </div>
          <div class="image"> <img src="assets/pics/09_small_fish_white.jpg" alt="Small Fish von Kiyoshi Furukawa">
          </div>
          <iframe src="https://player.vimeo.com/video/2375069" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

        <div class="videoblock">
          <p class="caption"> Visuelle und auditive Darstellung von abstrakten Daten, Datensonifikation und
            -visualisierung.
            (Beispiel: Mathematische Phänomene künstlerisch audiovisuell interpretiert von Max Cooper)</p>
          <iframe frameBorder="0" src="https://www.youtube.com/embed/O7bKq03bAsg" allow="autoplay; fullscreen"
            allowfullscreen> </iframe>
          <iframe src="https://player.vimeo.com/video/367747083" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

      </div>


      <div class="chap subchap" id="chap4">

        <h3>Bild-in-Klang-Übersetzung</h3>
        <p>Im Folgenden begann ich eine Untersuchung, wie man Bildaufnahmen in Klang übersetzen kann und ob sich so
          Aussagen machen lassen über Parallelen zwischen Bild und Klang. Dazu entwickelte ich ein Programm, das Bilder
          in
          Wellenformen umwandelt, die wiederum als akustische Wellen wiedergegeben werden.</p>

        <div class="videoblock videoblockSmall">
          <p class="caption"> Eigenes Tool zur Übersetzung geografischer Bilder in Klang mithile von Wavetable-Synthese
            (Max
            MSP).
            <br>
            <br>
          </p>
          <p class="caption" style="margin-bottom: 0">Anmerkungen zum Video:</p>
          <ul class="caption">
            <li>Ton beginnt ab 0:27.</li>
            <li>0:00 Demonstration des Tools: Das "Source Image" wird auf Kanten untersucht ("Edge Detection"). Diese
              Kanten sind die Grundlage der "Wavetable", welche den Klang erzeugt.</li>
            <li>1:05 Beispiele mit geometrischen Formen, die einen "reinen" Klang generieren.</li>
            <li>1:20 Verschiedene Beispiele mit Bilddaten von Google Maps.</li>
          </ul>
          <iframe src="https://player.vimeo.com/video/443345704" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

        <div class="videoblock videoblockSmall">
          <p class="caption"> Eigenes Bildmaterial zum Thema "Repetition" wird in Klang übersetzt.</p>
          <iframe src="https://player.vimeo.com/video/443345724" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>


        <div class="videoblock">

          <p class="caption">Weiterentwicklung der Echtzeitübersetzung von Kamerainput oder Videos in Klang mit
            Wavetable-Synthesis
            (Processing, eigene Aufnahmen, Film: Rhythmus 21, Hans Richter 1921).
          </p>
          <iframe src="https://player.vimeo.com/video/443346476" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443347123" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>
      </div>


      <div class="chap subchap" id="chap5">

        <h3>Konzept Live-Performance Tool</h3>
        <p>Es manifestierte sich die Idee, ein Live-Performance-Tool zu programmieren, das in Echtzeit Bilddaten in
          Musik,
          Bild und Bewegung
          übersetzt. Die Grundidee ist, dass visuelle Daten in für digitale Anwendungen lesbare Daten umgewandelt
          werden.
          Das Tool kann genutzt werden als elektronisches Musikinstrument, zur Generierung von Visuals als auch
          zur Steuerung motorischer Skulpturen. Das Tool so audiovisuellen Performern und Künstlern eine Möglichkeit
          bieten, die direkte Erfahrung der Umgebung
          in die Arbeit einfliessen zu lassen und damit zu improvisieren.
        </p>

        <div class="videoblock videoblockSmall">
          <p class="caption">Funktionsweise der Anwendung: Die App läuft auf dem Handy oder Laptop und liest
            Kameradaten.
            Die stark abstrahierten Daten, also beispielsweise der primäre Farbwert des Kamerabildes, werden in Open
            Sound
            Control (OSC) Signale umgewandelt, die dann via Internet an eine Schnittstelle (z.B. PC) geschickt werden.
            Die
            Daten können von den meisten gängigen Musik- und Videosynthese-Programmen erkannt werden, wo sie die Musik
            und
            Visuals erzeugen und manipulieren.</p>
          <div class="image"> <img src="assets/pics/skizze_app_v2.jpg" alt="Skizze App"> </div>
        </div>

        <div class="videoblock">
          <p class="caption"> Diese Videos zeigen einen ersten Protoytpen der beschriebenen Idee. Die horizontale
            Mitte eines Quellvideos (o.l.) wird in regelmässigen Abständen gemessen. Punkte ab einem bestimmten
            Helligkeits-Schwellenwert werden an das Musikprogramm (u.l.) gesendet und
            dort in Noten übersetzt. Die Y-Position der Punkte bestimmt dabei die Tonhöhe. Zudem werden die Werte in ein
            Programm zur Videoerzeugung (u.r.) geschickt, wo sie geometrisch-abstrakt umgesetzt werden.
            (Processing für Videoanalyse, Max MSP für Sound, Touchdesigner für Videogenerierung)
          </p>
          <iframe src="https://player.vimeo.com/video/443346671" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443346695" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
          <iframe src="https://player.vimeo.com/video/443346638" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>
      </div>


      <div class="chap subchap" id="chap6">

        <h3>Konzept Bewegtbild zu Musik</h3>
        <p>Das finale Konzept meiner gestalterischen Bachelorthesis ist ein Tool, das Bewegtbild in musikalische
          Kompositionen umwandeln kann. Dabei nimmt es verschiedene Aspekte des Bewegtbildes wie Helligkeiten, Farben,
          Bewegung und Konturen auf, quantifiziert diese Daten und wandelt sie in Melodien, Rhyhthmen und Geräusche um.
          <br>

        <div class="videoblock">
          <p class="caption"> Grundstock an Videoaufnahmen mit statischer Kamera und bewegten Elementen. (Eigene
            Aufnahmen)
          </p>
          <iframe src="https://player.vimeo.com/video/443347237?autoplay=1&loop=1&autopause=0" frameborder="0"
            allow="autoplay, fullscreen"></iframe>
          <iframe src="https://player.vimeo.com/video/443347273?autoplay=1&loop=1&autopause=0" frameborder="0"
            allow="autoplay, fullscreen"></iframe>
        </div>

        <div class="videoblock videoblockSmall">
          <p class="caption">
            Erster interaktiver Prototyp des Programmes. Auf der linken Seite können Video- und Audioeinstellungen
            vorgenommen werden, rechts könenn je nach ausgewähltem Modus
            Parameter der Bildanalyse eingestellt werden.
          </p>
          <iframe src="https://player.vimeo.com/video/443347328" frameborder="0" allow="autoplay; fullscreen"
            allowfullscreen></iframe>
        </div>

        <div class="videoblock">
          <p class="caption"> Verschiedene UI Entwürfe. Die Steuerungselemente sollten nicht das Bild abdecken, aber
            auch einfach zu erreichen sein. (Adobe XD)
          </p>
          <iframe src="https://player.vimeo.com/video/444973517?autoplay=1&loop=1&autopause=0" frameborder="0"
            allow="autoplay"></iframe>
          <iframe src="https://player.vimeo.com/video/444973515?autoplay=1&loop=1&autopause=0" frameborder="0"
            allow="autoplay"></iframe>
          <iframe src="https://player.vimeo.com/video/444973516?autoplay=1&loop=1&autopause=0" frameborder="0"
            allow="autoplay"></iframe>
        </div>
      </div>


    </div>

    <div class="chap" id="tool">
      <h2>Tool "Bildton"</h2>
      <p>Unter folgendem Link kann das Tool genutzt werden:
        <br><a href="https://rbvonrb.github.io/bildton" target="_blank">rbvonrb.github.io/bildton</a></p>
      <div class="videoblock">
        <p class="caption"> Demo Video
        </p>
        <iframe src="https://player.vimeo.com/video/453996298" frameborder="0" allow="autoplay; fullscreen"
          allowfullscreen></iframe>
      </div>
      <p>
        Das Tool funktioniert online und ohne Installation, der Quellcode ist frei verfügbar. Es kann auch in
        Kombination mit MIDI-kompatibler Soft- und Hardware genutzt werden. Ich habe für die Implementierung
        verschiedene Libraries benutzt, in erster Linie <a href="https://p5js.org/" target="_blank">P5.js</a> zur
        Bildanalyse und für die Interaktion sowie <a href="https://tonejs.github.io/" target="_blank">Tone.js</a> zur
        Generierung der Musik. Weitere Informationen und eine genauere Anleitung befinden sich auf der <a
          href="https://github.com/RBvonRB/Bildton" target="_blank">Github-Seite</a>, zusammen mit dem Sourcecode.
      </p>

    </div>

    <div class="chap" id="append">
      <h2>Anhang</h2>


      <div class="chap subchap" id="schrift">
        <h3>Kulturhistorische Thesisarbeit</h3>
        <div class="videoblock videoblockSmall">
          <div class="image"><a href="assets/schriftl_thesis_web.pdf" target="_blank"> <img src="assets/pics/thesis.png"
                alt="Kulturhistorische Bachelorthesis"></a> </div>
        </div>
      </div>

      <div class="chap subchap" id="contact">
        <h3>Kontakt</h3>
        <p>
          Portfolio: <a href="https://0764163012.ch" target="_blank">0764163012.ch</a><br>
          Instagram: <a href="https://instagram.com/rbvonrb" target="_blank">@rbvonrb</a><br>
          E-Mail: <a href="mailto:r.benz@live.com">r.benz@live.com</a>
        </p>
      </div>


      <div class="chap subchap" id="impr">
        <h3>Impressum</h3>

        <p>

          Raphael Benz, Basel <br>
          Bachelorthesis, FS 2020 <br>
          Institut Visuelle Kommunikation <br>
          FHNW HGK Basel <br>
          Mentoren: Prof. Marion Fink, Jinsu Ahn, Ted Davis <br>
          <br>
          Schrift: Neue Haas Grotesk Display & Text<br>
          <br>
          © Copyright 2020 by FHNW HGK /
          Raphael Benz <br>
          Alle Rechte vorbehalten –
          die Bildrechte liegen bei den Urhebern.
          <br>
          <br>
          <br>

        </p>

      </div>

    </div>

  </div>


  <script src="script.js" charset="utf-8"></script>

</body>

</html>